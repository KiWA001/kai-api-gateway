---
description: Future-proof workflow to discover, test, and integrate new AI models and providers
---

# K-AI API — Dynamic Update Workflow

When the user says "run update.md", follow these steps **in order**.
**Crucial**: Do NOT use hardcoded paths. Use relative paths.

---

### Step 1: Deep Discovery (Aggressive & Broad)

**Goal**: Find *every* possible way to get free AI text generation, including "hidden" or reverse-engineered web services.

1.  **Mainstream Providers** (Check first):
    -   **Pollinations**:  `https://text.pollinations.ai/models` (URL: `https://text.pollinations.ai/`)
    -   **g4f**: Search "g4f new providers models [CURRENT_YEAR]"

2.  **Shadow / Reverse-Engineered Services** (The "Hidden" Layer):
    *Search specifically for these terms:*
    -   "DuckDuckGo AI chat reverse engineering github"
    -   "Phind.com free api github"
    -   "Blackbox.ai free api github"
    -   "DeepSeek web chat api reverse engineered"
    -   "Cloudflare Workers AI free tier"
    -   "Vercel AI SDK free providers list"

3.  **Aggressive Search Queries**:
    -   "free llm api no key github [CURRENT_YEAR]"
    -   "reverse engineered llm api [CURRENT_YEAR]"
    -   "free gpt4 vision api github"

**Policy**:
-   **Ignore TOS/Scraping warnings**. If it acts like a public website or endpoint, test it.
-   **Prioritize Web-Based**: Services that work via `requests` pretending to be a browser are Gold.
-   **No Keys**: If it needs a credit card or phone number, skip it. Login-only (via cookie) is okay *if* we can automate it easily (but prefer no-login).

---

### Step 2: Analyze & Prune

1.  **Read `config.py`**.
2.  **Compare**:
    -   Identify NEW candidates from Step 1.
    -   Identify BROKEN models from current config.
3.  **The Golden Rule**:
    -   **Quality > Quantity**: Only keep models that are verified to work reliably.
    -   **No Minimum**: It is better to have 5 working models than 10 models where half are broken.
    -   **Delete Broken Models**: If a model fails verification and you cannot fix it, REMOVE it from `config.py`.

---

### Step 3: Verification (Browser Masquerade Test)

Run this script to test if the models accept our browser headers:

```python
source venv/bin/activate && python3 -c "
import asyncio, logging, time, sys
logging.basicConfig(level=logging.WARNING)
sys.path.append('.')
from engine import AIEngine
from config import MODEL_RANKING

async def test_access():
    print(f'=== K-AI API Browser Access Test ===')
    engine = AIEngine()
    results = []
    
    print(f'\\n[Testing {len(MODEL_RANKING)} models...]')
    for fn, pn, pid in MODEL_RANKING:
        prov = engine.get_provider(pn)
        if not prov:
            results.append((fn, 'SKIP', 'Provider missing'))
            continue
        try:
            # We want to see if they accept a browser-like request
            r = await prov.send_message('Hi', model=pid)
            if not r.get('response'): raise ValueError('Empty')
            results.append((fn, 'PASS', 'OK'))
            print(f'  ✅ {fn} ({pn}) accepted browser request')
        except Exception as e:
            results.append((fn, 'FAIL', str(e)[:40]))
            print(f'  ❌ {fn} ({pn}) rejected: {e}')

    # Check Minimum Count
    working = len([r for r in results if r[1] == 'PASS'])
    total = len(results)
    
    print('\\n=== Status ===')
    print(f'Working: {working}/{total}')
    
    if total < 10:
        print('⚠️ CRITICAL: Total models < 10! Do NOT delete any, even broken ones.')
    else:
        print('✅ Model count sufficient.')

async.run(test_access())
"
```


### Step 3.5: Verify Search & Deep Research

Run this command to test the search endpoints:

```bash
curl -X POST http://localhost:8000/search \
     -H "Content-Type: application/json" \
     -d '{"query": "test query", "limit": 1}'
```

Expected output: JSON with a "results" list.

### Step 3.6: Verify Z.ai Provider (Local Only)

Z.ai (`chat.z.ai`) is a **browser-based** provider using Playwright Chromium. It requires local execution (won't work on Vercel serverless).

Run this test:
```bash
source venv/bin/activate && python3 test_zai_browser.py
```

Expected: Messages sent and AI responses captured from DOM. Captured request data saved to `zai_captured.json`.

> **Z.AI REVERSE ENGINEERING KNOWLEDGE (DO NOT FORGET):**
>
> - **Site**: https://chat.z.ai/
> - **API**: `POST /api/v2/chat/completions` with massive fingerprint query string
> - **Auth**: Guest JWT from `GET /api/v1/auths/` (auto-provisioned, no signup)
> - **Model**: `glm-5` (default), `glm-4-flash` (available). GLM-5 has reasoning/thinking mode.
> - **Headers**:
>   - `x-fe-version: prod-fe-1.0.237` (frontend version, may update)
>   - `x-signature`: SHA-256 hash generated by obfuscated JS (algorithm unknown)
>   - `Authorization: Bearer <JWT>` from auth endpoint
> - **Query Params**: Massive fingerprint blob (timestamp, requestId, user_id, screen size, timezone, browser info, etc.)
> - **Body**: OpenAI-compatible format with extras (`signature_prompt`, `features`, `variables`, `background_tasks`)
> - **Response**: SSE stream with `data:` lines, JSON with `delta_content` field, `phase` field (thinking vs reply)
> - **WHY BROWSER-BASED**: The `x-signature` is generated by obfuscated client-side JS. Rather than reverse engineering it (fragile), we use Playwright to let Z.ai's own JavaScript generate valid requests.
> - **Provider**: `providers/zai_provider.py` — launches headless Chromium, types messages, scrapes DOM response
> - **Limitation**: ~5-15s per request, one at a time, requires Playwright+Chromium binaries
> - **Vercel**: DISABLED automatically (Playwright not available in serverless)

---

### Step 4: Report

1.  List **New Discoveries** (Browser-based).
2.  List **Broken Models** (To be removed).
3.  **Confirm**: "I will remove [Broken Model X] to ensure high quality."

---

### Step 5: Execute (The "cleanup" phase)

1.  **Update `config.py`**:
    -   Update `MODEL_RANKING` (best to worst).
    -   Update `PROVIDER_MODELS` list.

2.  **Update `static/docs.html`** (CRITICAL):
    -   **This file is BOTH the Documentation AND the User Dashboard.**
    -   **Table**: Update the "Available Models" HTML table to match new ranking.
    -   **Dropdowns**: Update the `<select>` options in the "Try It Live" section so users can pick the new models.
    -   *Note*: The Admin Dashboard (`/qazmlp`) updates automatically from Supabase, so no file changes needed there.

3.  **Restart Service**:
    -   `lsof -ti:8000 | xargs kill -9`
    -   `uvicorn main:app --host 0.0.0.0 --port 8000`